Chiamiamo $\hat \theta = T(\mathcal D)$ ogni stimatore che sia funzione dei dati. Consideriamo il MSE nel caso scalare $MSE = \mathbb E[(\hat \theta - \theta)^2] = \mathbb E[(T(\mathcal D)-\theta)^2]$. Definiamo *stimatore ottimo di Bayes* lo stimatore $T^{opt}(~)$ tale da avere il minimo MSE tra tutti i possibili stimatori. Esso ha il valore atteso condizionato della variabile:
$$T^{opt} (Y) = \mathbb E[\theta | \mathcal D = Y]$$
Supponiamo di avere un parametro scalare ignoto $\theta \sim \mathcal N(0, \lambda_{\theta\theta}^2)$ che sia realizzazione di una variabile casuale gaussiana e di avere un singolo dato $y \sim \mathcal N(0, \lambda_{yy}^2)$ anch'esso realizzazione di una variabile casuale gaussiana. Allora la funzione di densità di probabilità congiunta, una bivariata, è anch'essa gaussiana, così come è gaussiana la distribuzione a posteriori. In particolare, essa avrà i seguenti valori di media e varianza:

- $\mu_{\theta | y} = \frac{\lambda_{\theta y}}{\lambda^2_{yy}} \cdot y$
- $\lambda^2_{\theta|y} = \lambda_{\theta \theta}^2 - \frac{\lambda^2_{\theta y}}{\lambda^2_{yy}}$

Notiamo che il secondo termine nella varianza è sempre negativo, quindi l'incertezza della distribuzione a posteriori (la varianza) è minore rispetto a quella a priori. Interpretiamo questo fenomeno come l'aumento dell'informazione grazie all'arrivo dei dati. A denominatore di tale secondo termine abbiamo la varianza dei dati che, crescendo, abbassa il termine. Dati ad alta varianza, infatti, portano poca informazione.


Non sempre il dato e il parametro sono congiuntamente gaussiani. Rimuovendo questa ipotesi, proviamo a costruire uno stimatore solamente sapendo che le due variabili sono casuali, i loro valori attesi sono entrambi nulli, e che le loro varianze sono definite.
$$\hat \theta^{lin} = \alpha \cdot y + \beta, \quad \alpha, \beta \in \mathbb R$$
Possiamo ottenere uno stimatore ottimo minimizzando il MSE rispetto ai due parametri $\alpha$ e $\beta$. Lo stimatore lineare ottimo è pari a
$$ \hat \theta_{opt}^{lin} = \hat \alpha \cdot y + \hat \beta = \frac{\lambda_{\theta y}}{\lambda^2_{yy}} \cdot y. $$
Possiamo notare la somiglianza alla formula del valore atteso per il caso gaussiano. Lo stimatore lineare ottimo è il migliore stimatore che si possa ottenere non facendo ipotesi. Aggiungendo ipotesi aggiuntive si può ottenere una stima più precisa, a meno che non si tratti di un'ipotesi gaussiana. In tal caso, il miglioramento è nullo perché le formule coincidono. Esistono versioni generalizzate dello stimatore lineare ottimo per casi con valore atteso non nullo e per parametri vettoriali. Le formule dello stimatore lineare ottimo ammettono una formula ricorsiva. Essa permette di non dover ricalcolare l'intero stimatore all'arrivo di un nuovo dato, basandosi invece sulla stima precedente. Questa proprietà è particolarmente utile per i sistemi dinamici. Un'applicazione in tale ambito è il *filtro di Kalman*, un algoritmo che stima lo stato di un sistema dinamico in funzione di un ingresso in serie storica. Lo stato attuale è la stima a priori, mentre gli ingressi del sistema sono i nuovi dati osservati. La predizione dello stato all'istante successivo è la stima a posteriori.

# Sistemi dinamici

D'ora in avanti il termine *sistema ingresso-uscita* farà riferimento a un sistema SISO LTI. Questi modelli lavorano con ingressi in serie storica. Solitamente questi modelli sono costruiti come unione di due modelli secondari, di cui uno modella la componente nota e l'altro il disturbo. Il termine di disturbo modella disturbi quali: errori di misura; disturbi di processo ed effetti di segnali esogeni non misurabili nell'ingresso; effetti della linearizzazione del sistema. Entrambi i termini, componente nota e disturbo, sono modellizzati come funzioni di trasferimento di sistemi SISO LTI a tempo discreto. Distinguiamo tra sistemi ingresso uscita propriamente detti, e *serie temporali*, ovvero modelli il cui ingresso non è misurabile. A livello implementativo le serie temporali sono rappresentate come serie storiche il cui ingresso è utilizzato come ausilio matematico. Per entrambi i tipi di modello ci si pongono due obiettivi. Innanzitutto si vuole prevedere l'uscita a istanti futuri $t+k$ in base alle informazioni presenti a $t$: $\hat y (t+k|t)$. Si desidera inoltre identificare (ovvero stimare, nel gergo dei modelli dinamici) i modelli descritti. Queste due fasi devono essere precedute da un'adeguata fase di scelta della classe dei modelli da impiegare. Per convenzione, lavorando d'ora in avanti con modelli a tempo discreto con periodo di campionamento $T_s$, si intenderà implicitamente $y(t) = y(t \cdot T_s)$.

Si assuma che l'uscita del modello sia sempre affetta da un disturbo e che anch'essa sia funzione della variabile temporale. In un modello statico il disturbo è rappresentabile come una variabile casuale. In un modello dinamico il disturbo è invece da intendersi come una successione di variabili casuali. Tale successione prende il nome di *processo stocastico*. Un processo stocastico è una successione infinita di variabili casuali definite a partire dallo stesso esperimento casuale, e ordinate secondo un indice temporale. Fissando l'esito si ottiene la realizzazione; fissando il tempo si ottiene una variabile casuale; fissando entrambi si ottiene un numero. I processi stocastici sono utili per analizzare fenomeni che non si possono (o non si vogliono) descrivere in modo analitico e deterministico. Un processo stocastico è completamente caratterizzato dal punto di vista probabilistico se per ogni sottoinsieme di variabili casuali è definita la congiunta. Un esempio di processo stocastico è il *random walk.* Ad ogni passo il valore assunto dal processo è pari alla somma valore del passo precedente con la realizzazione di una variabile casuale.

Un processo stocastico è completamente caratterizzato a livello probabilistico se è definita la distribuzione congiunta per ogni sottoinsieme di sue variabili casuali. Per i processi discreti, questo implica di dover conoscere la distribuzione di probabilità congiunta di un numero infinito di variabili casuali. A meno che non si tratti di variabili gaussiane o pochi altri casi facilmente studiabili, questa assunzione è inottenibile. Spesso, dunque, non ci si può spingere oltre alla stima del valore atteso e della funzione di covarianza o *autocorrelazione*, detta *caratterizzazione del secondo ordine*. Il valore atteso, momento del primo ordine, è funzione del tempo e rappresenta la media tra le possibili realizzazioni del processo stocastico ad un determinato istante. Non va confuso con la *media storica*, ovvero la media dei valori effettivamente realizzati dal processo durante la sua evoluzione temporale. L'autocorrelazione, invece, si può intendere come la correlazione di una variabile con sé stessa ad istanti diversi. Un concetto simile è l'autocovarianza, ovvero la covarianza di una variabile con sé stessa ad istanti diversi. Imponendo due tempi uguali, otteniamo la varianza della variabile. Una generalizzazione è l'*autovarianza normalizzata*, per il cui calcolo l'autovarianza viene divisa per la radice quadrata del prodotto delle varianze ai due tempi. Essa viene calcolata da Matlab al posto della covarianza.

Si parli ora di *processi stocastici congiunti*. Dati due processi stocastici $v$ e $x$, si possono definire le loro funzioni di *cross-correlazione* e *cross-covarianza*: 
$$R_{vx}(t_1, t_2) \equiv \mathbb E_s[v(t_1, s) \cdot x(t_2, s)] = R_{xv}(t_2, t_1) $$
$$\gamma_{vx} (t_1, t_2) \equiv \mathbb E[(v(t_1, s)-m_v(t))\cdot(x(t_2,s)-m_x(t))] = \gamma_{xv} (t_2, t_1)$$
Due processi stocastici si dicono incorrelati se la loro cross-covarianza è sempre nulla. Anche per la cross-covarianza esiste una versione normalizzata.

