## Predizione, filtraggio e smoothing

Dati due processi stocastici stazionari  $x(t)$ e $y(t)$ di cui uno solo osservabile ($y$), analizziamo il problema di stimare il processo ignoto $x$ a partire da quello noto $y$. Il problema ha due casi:

- *caso banale*: i due processi sono uguali
- *caso comune*: $y(t) = x(t) + e(t)$, $e(t) \sim WN(0,\lambda^2)$, ovvero misuriamo tramite $y$ una versione rumorosa di $x$

Vogliamo ottenere una stima a posteriori di $x$ a tempi dato il valore ad un tempo dato, dato $y$. Se la stima avviene per tempi successivi a quello dell'osservazione, si parla di *predizione*. Se la stima avviene per un tempo uguale al tempo dell'osservazione, si parla di *filtraggio*. Se infine si stimano tempi precedenti a quello dell'osservazione di riferimento, si parla di *smoothing*. Quest'ultimo, al contrario degli altri due, non è effettuabile in tempo reale.

Analizziamo il caso della *predizione a $k$ passi*. Consiste nel cercare di ottenere $\hat x(t|t-k)$, ovvero stimare $x(t)$ date le informazioni al più fino al tempo $t-k$ incluso. Si tratta, dunque, di una stima per istanti futuri a quello dell'osservazione. La stima per il momento presente data un'osservazione passata corrisponde, a livello di formula, alla stima futura data un'osservazione presente ($\hat x(t+k|t)$), purché $k$ sia il medesimo. Questa proprietà è valida solo per i processi stazionari. Si considerino ora i due casi rimanenti, filtraggio e *smoothing.* Il filtraggio consiste nella stima di $\hat x(t|t)$, ovvero ottenere una stima di $x$ all'istante corrente, pulita dal rumore. L'operazione ha senso solo se la misurazione $y(t)$ è diversa dal vero segnale $x(t)$ a causa di errori. Lo *smoothing* invece è l'operazione di stima $\hat x(t|t+k)$, che ripulisce il segnale a tempi passati, al fine di ricostruire la traiettoria del segnale ripulita dal rumore. Esattamente come il filtraggio, anche lo *smoothing* ha senso solo se la misurazione è diversa dal vero segnale a causa di errori.

### Predizione ottima

Analizziamo la stima di $y(t)$ come $\hat y(t|t-k)$ sapendo che $x(t) = y(t)$. Dato che $y$ è un processo stocastico, anche il predittore $\hat y$ basato sui valori passati di $y$ è a sua volta un processo stocastico. Anche l'errore di predizione è un processo stocastico per la medesima ragione, e si definisce come:
$$\varepsilon_k (t) = y(t) - \hat y(t|t-k).$$

È desiderabile ottenere *predittori lineari ottimi*, che abbiano cioè un errore di predizione a MSE minimo. Consideriamo i predittori ottimi per ARMA e ARMAX, escludendo gli altri tipi di modelli, perché a fine analisi si arriva ad un'espressione generale valida anche per le altre famiglie.
Riprendendo quanto spiegato in precedenza, $\hat y(t|t-k)$ e $\hat y(t+k|t)$ potrebbero avere valori diversi a livello numerico, ma sono caratterizzati dalla stessa formula del predittore ottimo.

Un processo stocastico stazionario si definisce *completamente predicibile* se esistono coefficienti per la formula:
$$ y(t) = \sum_{i=1}^{+\infty} a_i y(t-i) $$
che permettano di prevedere $y(t)$ senza alcun errore. Un processo completamente predicibile è caratterizzato da una formula della densità spettrale di potenza nella seguente forma:
$$ \Gamma_{yy}(\omega) = \sum_i \alpha_i \delta(\omega - \omega_i)$$
dove $\delta$ è detto *delta di Dirac* e produce una rappresentazione puntuale di una singola frequenza sinusoidale sul grafico. La densità spettrale di potenza di un processo completamente predicibile è dunque una combinazione lineare di delta di Dirac. Per contro, il segnale completamente impredicibile, il rumore bianco, ha densità spettrale di potenza costante, non rappresentabile come combinazione lineare di un numero finito di termini puntuali.

Un esempio è una somma di funzioni sinusoidali / cosinusoidali a coefficienti casuali incorrelati. con $\mathbb E [v_1] = \mathbb E [v_2]$ e $\mathrm{Var} [v_1] = \mathrm{Var} [v_2] = \sigma^2$:
$$y(t) = v_1 \sin(\bar \omega t) + v_2 \cos( \bar\omega t).$$
Il processo $y$ è stazionario, non ergodico, con funzione di autocovarianza cosinusoidale. La densità spettrale di potenza è perfettamente a spilli. Dopo aver stimato i coefficienti, il processo diventa perfettamente predicibile in modo deterministico e periodico.

### Scomposizione di Wold
Possiamo scrivere ogni processo stocastico stazionario come somma di due componenti totalmente incorrelate, una completamente predicibile e l'altra completamente stocastica:
$$y(t) = \bar y(t) + y_p(t)$$
$\bar y(t)$ tale che $\bar y(t) = \sum_{i=0}^{+\infty} c_i e(t-i)$, con $e$ che è una realizzazione del rumore bianco.

La parte puramente stocastica può essere interpretata come un $MA(\infty)$. Anche la densità spettrale di potenza si può scomporre come la somma di un grafico a spilli, dovuto alla parte deterministica, e un grafico continuo, dovuto alla parte stocastica. Nella pratica la scomposizione fornisce una linea guida per stimare modelli di serie temporali. Per effettuare tale stima, bisogna innanzitutto osservare i dati o lo spettrogramma per riconoscere le componenti periodiche. Successivamente si stimano, manualmente o ai minimi quadrati, le componenti $y_p(t)$ necessarie per ottenere $\hat y_p(t)$. Dopodiché è possibile estrarre la componente puramente stocastica come differenza tra il segnale complessivo $y(t)$ e la componente deterministica appena stimata. Per effettuare predizioni, si predicono separatamente la componente deterministica e quella stocastica, e se ne sommano le predizioni.
In particolare, la stima dei *trend* sinusoidali può essere effettuata riconoscendo innanzitutto il periodo, e poi campionandone l'ampiezza a intervalli costanti su un numero finito di periodi, per calcolarne la media, come mostrato in figura:

\begin{tikzpicture}[domain=0:16,samples=300]
\draw[very thin,color=gray] (-0.1,-1.1) grid (16,3.9);
\draw[color=blue] plot (\x,{2*sin(3 * \x r) + rand*0.2 });


\foreach \x in {0,2.09,...,16} {
        \pgfmathsetmacro{\y}{2*sin(3 * \x r)}
        \fill[red] (\x,\y) circle (4pt);
    }4
\foreach \x in {0.1,2.19,...,16} {
        \pgfmathsetmacro{\z}{2*sin(3 * \x r)}
        \fill[green] (\x,\z) circle (4pt);
    }
\foreach \x in {0.2,2.29,...,16} {
        \pgfmathsetmacro{\q}{2*sin(3 * \x r)}
        \fill[orange] (\x,\q) circle (4pt);
    }
\foreach \x in {0.3,2.39,...,16} {
        \pgfmathsetmacro{\w}{2*sin(3 * \x r)}
        \fill[yellow] (\x,\w) circle (4pt);
    }

\end{tikzpicture}

In questo caso calcoleremo la media degli 8 punti rossi, degli 8 punti verdi, ecc. per avere un campionamento dell'ampiezza della sinusoide in vari punti e ricavarne il *trend*.

Come ipotesi di lavoro, assumiamo che il processo $MA(\infty)$ possa essere approssimato da processi a spettro razionale, per poter impiegare modelli ARMA o simili.
Esiste una categoria di modelli detti SARMA, che sono modelli ARMA in grado di stimare direttamente anche la stagionalità senza bisogno di essere scomposti manualmente.
Non è sempre facile estrarre le componenti deterministiche dal periodogramma. Questo perché gli stimatori della densità spettrale di potenza tendono a non essere buoni, e le risonanze nel grafico potrebbero non essere delta di Dirac ma picchi dovuti ai poli della funzione di trasferimento.

Definiamo *filtro passa-tutto* un filtro che non filtra, cioè che lasci passare tutte le componenti. La sua funzione di trasferimento è:
$$ T(z) = \frac 1 a \cdot \frac{z+a}{z+\frac 1 a}, \quad a \neq 0, a \in \mathbb R. $$Calcolando la densità spettrale di potenza del segnale in uscita quando il segnale in ingresso è un processo stocastico stazionario, ci si accorge che è la stessa del segnale in ingresso. Il segnale in uscita non è però identico, perché il filtro causa uno sfasamento.
