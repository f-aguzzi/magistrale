## Limiti temporali

Un problema computazionale ha complessità $O(f(n))$ *(upper bound)* se esiste un algoritmo per la sua risoluzione con complessità $O(f(n))$. Un problema computazionale ha complessità $\Omega(f(n))$ *(lower bound)* se ogni algoritmo per la sua risoluzione ha complessità $\Omega(f(n))$.
Riuscendo a dimostrare che un problema ha delimitazione inferiore $\Omega(f(n))$, e trovando un algoritmo che ha delimitazione superiore $O(f(n))$, allora si ottiene, a meno di costanti, un algoritmo risolutivo ottimale.

Per la ricerca del minimo in insiemi non ordinati di $n$ elementi la complessità inferiore è $\Omega(n)$ perché è necessario scandire almeno una volta l'intero insieme. Un algoritmo $O(n)$ è dunque ottimo. Il *mergesort* ha complessità $n \log n$ per un problema $n \log n$ ed è dunque ottimale. Il *bubblesort* è subottimale perché ha complessità $n^2$.

La dimensione dell'*input* non è il solo criterio in base al quale valutare l'esecuzione degli algoritmi. Distinguiamo caso migliore, peggiore, medio.
Dato $\mathrm{tempo} (I)$ il tempo di esecuzione dell'algoritmo sull'istanza $I$, abbiamo
$$T_{worst} (n) = \max_{\text{istanze } I \text{ di dimensione }n} \{ \mathrm{tempo}(I)\}$$
$$T_{best} (n) = \max_{\text{istanze } I \text{ di dimensione }n} \{ \mathrm{tempo}(I)\}$$
$$T_{avg} (n) = \sum_{\text{istanze } I \text{ di dimensione }n} \{ \mathcal P(I)~ \mathrm{tempo}(I)\}$$
dove $\mathcal P(I)$ è la distribuzione di probabilità dei casi.

Per la ricerca sequenziale (cerca lungo l'intera lista, fermati alla prima istanza trovata), il tempo migliore è 1 (elemento cercato in testa), il peggiore è $n$ (elemento in ultima posizione), media $(n+1) / 2$. Questo vale se assumiamo che le istanze siano equidistribuite e che la probabilità di ogni elemento sia $1/n$. Applicando la formula di prima esce la probabilità del caso medio (serie aritmetica).

Spesso il calcolo del caso medio è molto complesso e, in molti casi, si scopre che il caso medio è molto vicino al caso peggiore. Pertanto, è spesso conveniente determinare il limite superiore nel caso peggiore.

La ricerca binaria per liste ordinate si basa su tre indici: inferiore, medio, superiore. Ad ogni passo si confronta l'elemento all'indice medio con il *target* della ricerca. In caso di differenza, restringiamo la ricerca alla metà corrispondente di lista. In un numero finito di passi l'algoritmo collassa su di un solo elemento. Se esso non è quello cercato, la ricerca fallisce. In alcuni casi può capitare che gli indici si incrocino, e anche in questo caso si può dedurre che l'elemento cercato non sia presente in lista. Il tempo migliore è costante (l'elemento centrale è quello cercato, e viene trovato subito): $\Theta(1)$. Il tempo peggiore si ha quando l'elemento cercato è l'ultimo considerato, o non c'è. Dato che si procede per dimezzamenti della lista, il numero di passi è pari $\log_2 n$ del numero di elementi. Il caso medio è $\log n - 1 + \frac 1 n$, simile al caso peggiore.

# Strutture dati

Si analizzeranno ora le strutture dati nell'ottica dell'analisi degli algoritmi. Si introduca innanzitutto il concetto di *Abstract Data Type*. Esso risponde alla domanda *"che cosa?"*, nel senso che definisce la semantica, le operazioni correlate, gli ingressi, le uscite e i vincoli legati al tipo di dati in questione. La struttura dati vera e propria, invece, è una concretizzazione dell'ADT, e risponde alla domanda *"come?"*, fornendo i dettagli implementativi. Nella programmazione a oggetti, gli ADT corrispondono alle interfacce, mentre i tipi concreti corrispondono alle classi. Per fornire un esempio, definiamo astrattamente un dizionario. I dati sono un insieme di coppie chiave / valore. Le operazioni consentite sono l'inserimento (aggiunta di una nuova coppia all'insieme), la cancellazione (rimozione di una coppia dall'insieme data la sua chiave) e ricerca (recuperare una coppia dall'insieme data la chiave). Volendo essere più precisi, potremmo anche definire il tipo di ritorno di ogni operazione, compreso il valore restituito in caso di errori. In Java, la definizione prende la forma seguente:

```java
public interface Dizionario {
	public void insert(Object e, Comparable k);
	public void delete(Comparable k);
	public Object search(Comparable k);
}
```

Questa implementazione è non generica (usiamo `Object` e la versione non generica di `Comparable`). Volendo sfruttare i tipi generici, invece:

```java
public interface Dizionario <E, K extends Comparable <? Super k >> {
	public void insert(E e, K k);
	public void delete(K k);
	public E search(K k);
}
```

## Rappresentazioni indicizzate e collegate

Le tecniche di rappresentazione dei dati possono essere divise in due categorie: *rappresentazioni indicizzate* e *rappresentazioni collegate*. Il primo raggruppamento memorizza i dati in aree contigue di memoria, come in un *array*. Questo permette di accedere direttamente ai dati tramite un indice. Di contro, però, la dimensione è fissa, causando spreco di spazio dovuto alla frammentazione interna, da mitigare con riallocazioni frequenti che richiedono un tempo lineare. Il secondo tipo utilizza invece *record* spazialmente separati, ma collegati logicamente da puntatori. L'effettiva compattezza e lo spazio occupato dipendono dalla specifica implementazione. Esempi di struttura collegata sono la lista semplice, la lista doppiamente collegata e la lista circolare doppiamente collegata. Le rappresentazioni collegate hanno dimensioni variabili, veramente dinamiche. Le aggiunte e le rimozioni sono effettuate a tempo costante. L'accesso dei dati invece richiede un tempo medio lineare, perché è necessariamente sequenziale.

Riprendiamo l'esempio relativo all'implementazione del dizionario. Volendolo costruire come struttura dati collegata, possiamo basarlo sull'array. L'inserimento di una nuova coppia richiede la riallocazione dell'array. Si alloca un nuovo spazio di memoria con lo spazio per un elemento in più. Successivamente lo si riempie copiando il contenuto della versione precedente dell'array finché non si raggiunge l'elemento precedente, in ordine di chiave, rispetto all'elemento da inserire. Si inserisce infine l'elemento nuovo, e dopo di esso tutti gli elementi preesistenti che lo seguono in ordine di chiave. La cancellazione richiede di trovare prima l'indice dell'elemento da cancellare, e in seguito di riallocare l'array con un posto in meno, saltando nella copia l'elemento da scartare. Entrambe le operazioni di inserimento e cancellazione hanno tempo lineare. Dato che l'array è ordinato, la ricerca può essere effettuata in tempo logaritmico sfruttando l'algoritmo di ricerca binaria.
Un'implementazione collegata del dizionario può essere generata utilizzando una lista collegata. Le nuove coppie si inseriscono in testa, a tempo costante. L'operazione, infatti, richiede l'aggiornamento di un puntatore (quello della testa, se la lista è vuota) o due puntatori (testa e riferimento al successivo, se la lista non è vuota). L'eliminazione è a tempo lineare perché richiede di scandire sequenzialmente la lista per trovare l'elemento desiderato, e di riscrivere i puntatori per collegare tra loro gli elementi precedente e successivo ad esso. Anche la ricerca è sequenziale e dunque a tempo lineare.

Definiamo la struttura dati astratta per una pila. Si tratta di una semplice sequenza di elementi, e la particolarità sta nella politica d'accesso LIFO (*Last In, First Out*). Possiamo definire operazioni per verificare se sia vuota o meno, per inserire ed eliminare elementi dalla cima, o per osservare tale cima in sola lettura. Anche la pila, come il dizionario, può essere implementata come struttura indicizzata o collegata. Una possibile implementazione indicizzata in Java prende la forma seguente:
```java
public interface Pila {
	private int maxSize;
	private int top;
	private Object[] listArray;
}

class LPila implements Pila {
	private Record top;
	private int size;
	...
}
```

La struttura dati astratta di una coda deve permettere due operazioni (*enqueue*, "accoda", e *dequeue*, "rimuovi"), e di accedere in sola lettura all'estremo di interesse. La coda può anche essere bilaterale (nota come *deque*, ovvero *Double-Ended QUEue*), e permettere accodamento e scodamento di elementi da entrambi gli estremi. L'implementazione indicizzata di una coda può essere effettuata tenendo due indici, *front* e *rear*, per il primo e ultimo elemento della coda all'interno del vettore. Dato che inserimenti e cancellazioni possono lasciare spazi vuoi sia in testa che in coda, conviene interpretare l'array come una struttura circolare e leggerlo "a orologio" lungo un verso stabilito. Questo riduce la necessità di riallocazioni dovute al ricompattamento dei dati. A livello implementativo l'effetto può essere ottenuto usando l'aritmetica modulare nel calcolo degli indici. In questa versione circolare è possibile distinguere tra coda piena e vuota soltanto se è presente almeno uno spazio vuoto tra il primo e l'ultimo elemento. Non è possibile infatti dedurre dagli indici *front* e *rear* se l'array sia completamente pieno o completamente vuoto, perché in entrambi i casi la loro posizione si sovrappone.
L'implementazione collegata per le code e le pile è molto semplice da gestire. Tutte le operazioni sono a tempo costante perché si opera sempre e solo sugli elementi in testa (o eventualmente in coda).
