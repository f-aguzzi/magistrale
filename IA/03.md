
Classificazione dell'ambiente:

- completamente o parzialmente osservabile
- deterministico (stato successivo = stato corrente + effetti delle azioni dell'agente) o non deterministico
- episodico (l'azione dell'agente influenza solo l'episodio corrente) o sequenziale (azioni correnti hanno effetto percepibile in istanti futuri)
- statico (influenzato solo dalle azioni dell'agente) o dinamico
- discreto o continuo (in base alla cardinalità del tempo e delle azioni)

# Complessità degli algoritmi

*Algoritmo*: sequenza finita di operazioni non ambigue ed effettivamente calcolabili che, una volta eseguite, producono un risultato in una quantità di tempo finita.

Questo implica che serva una condizione d'uscita finita nei cicli contenuti nell'algoritmo.

Un algoritmo è indipendente dal modello di calcolo che lo concretizza.

Gli algoritmi devono avere due caratteristiche fondamentali:

- *correttezza*: produzione del risultato desiderato
- *efficienza*: minimizzazione del tempo di esecuzione e dell'occupazione di memoria

Si analizzano gli algoritmi e non i programmi, perché l'analisi teorica è più generica e affidabile di quella sperimentale. Permette di scegliere tra diverse soluzioni alternative e di scegliere l'implementazione più conveniente in base a fattori teorici.

Si rappresentano il tempo e lo spazio in funzione delle dimensioni del problema: $t(n)$, $s(n)$. Per evitare l'influsso di istruzioni spurie, fattori additivi e moltiplicativi, si esegue un'*analisi asintotica* dell'impiego di risorse degli algoritmi.

Le notazioni $O$ e $\Omega$ rappresentano, rispettivamente, i limiti superiori e inferiori dell'andamento di una funzione. La notazione $\Theta$ rappresenta un limite stretto.

- $f(n) = O(g(n))$ se $\exists$ $c>0$, $n>0$ $/$ $f(n) \le cg(n)$ $\forall n \ge 0$ (limite superiore asintotico)
- $f(n) = \Omega(g(n))$ se $\exists$ $c>0$, $n>0$ $/$ $f(n) \ge cg(n)$ $\forall n \ge 0$ (limite inferiore asintotico)
- $f(n) = O(g(n))$ se $\exists$ $c_1>0$, $c_2 > 0$, $n>0$ $/$ $c_1 g(n) \le f(n) \le c_2g(n)$ $\forall n \ge 0$ (limite stretto asintotico)

Avviene un abuso di notazione: sarebbe più corretto scrivere $f(n) \in O(g(n))$ perché si tratta di famiglie di funzioni.

La notazione $O$ gode di proprietà transitiva. Valgono per esse alcune regole di semplificazione:

- *eliminazione*: $O(kg(n)) = O(g(n))$
- *somma*: $O(g_1(n)) + O(g_2(n)) = O(\max(g_1(n),g_2(n)))$
- *prodotto*: $O(g_1(n)) \cdot O(g_2(n)) = O(g_1(n) g_2(n))$

Le principali classi sono:

- $O(1)$: *costante*
- $O(\log(n))$: *logaritmico*
- $O(n)$: *lineare*
- $O(n \log(n))$: *pseudolineare*
- $O(n^2)$: *quadratica*
- $O(k^n)$: *esponenziale*
- $O(n^k)$: *polinomiale*

La complessità intrinseca di un problema è collegata ma non coincidente alla complessità di uno specifico algoritmo risolutivo. La soluzione trovata, infatti, potrebbe essere più complessa rispetto a quanto richiesto dal problema, ma non può mai essere inferiore. Formalmente:

> Un algoritmo ha complessità $O(f(n))$ se $\exists$ un algoritmo risolutivo con delimitazione superiore $O(f(n))$.
>
> Un algoritmo ha complessità $\Omega(f(n))$ se tutti gli algoritmi risolutivi hanno delimitazione inferiore $\Omega(f(n))$.

Se il problema ha delimitazione inferiore $\Omega(f(n))$ e consideriamo una soluzione $O(f(n))$, allora tale soluzione è ottimale a meno di costanti.


## Problemi di decisione

I *problemi di decisione* ammettono una soluzione booleana determinata. Un *algoritmo di decisione* è un algoritmo che termina per ogni possibile input. Un problema di decisione si dice *decidibile* se esiste almeno un algoritmo di decisione per esso. Esistono problemi dimostrabilmente indecidibili.

I problemi si analizzano sulla base delle prestazioni dell'algoritmo migliore nel caso peggiore. Si fa riferimento al modello di calcolo astratto della macchina di Turing.

- $\mathrm{TIME}(f(n))$: famiglia dei problemi risolvibili in tempo $O(f(n))$
- $\mathrm{SPACE}(f(n))$: famiglia dei problemi risolvibili con occupazione di memoria $O(f(n))$

*Classe di complessità*: insieme dei problemi risolvibili al massimo in $C(n)$.

Un problema è *polinomiale nel tempo* (appartenente alla classe $\mathrm{PTime}$ o $P$) se esiste un algoritmo di classe $O(n^k)$ deterministico.

Un problema è *trattabile* se è possibile trovare agevolmente soluzioni per $n$ grande.

Un problema è *non deterministico* / appartenente alla classe $\mathrm{NPTime}$ o $NP$ se il suo algoritmo risolutivo migliore è esponenziale. Questo porta alla necessità di alberi di ricerca molto estesi e ramificati, o all'uso di una macchina di Turing non deterministica (non realmente esistente).

I problemi $NP$ sono intrattabili. Un possibile modello che approssimi la macchina di Turing non deterministica consiste nel trovare soluzioni casuali la cui ottimalità possa essere verificata in tempo polinomiale (approccio *guess-and-check*).

Si ipotizza (ma non è ancora stato dimostrato) che $P \ne NP$.

Un'altra classe è $CoNP$, che include i problemi il cui complemento sia in $NP$. Il complemento consiste nel determinare se una data istanza ha risposta negativa. Una soluzione e quella del suo complemento possono essere diverse.

Si ipotizza (ma non è ancora stato dimostrato) che $CoNP \ne P \ne NP$.

Altre classi:

- $\mathrm{PSpace}$ (che può essere $NPTime$)
	- problemi considerati più difficili degli $NP$
	- risolvibili in spazio polinomiale da una macchina di Turing deterministica
- $\mathrm{ExpTime}$: $\mathrm{TIME}(k^n)$ per macchina di Turing deterministica
- $\mathrm{NExpTime}$: $\mathrm{TIME}(k^n)$ per macchina di Turing non deterministica

Classi inferiori a $P$:

- $\mathrm{LogSpace}$ vs $\mathrm{NLogSpace}$: risolvibili in spazio logaritmico da macchine di Turing qualsiasi
	- si conta solo lo spazio di lavoro, non quello occupato dall'input
- $AC0$: $O(k)$ da $n^k$ processori in parallelo
	- è la classe di complessità delle operazioni sui database
