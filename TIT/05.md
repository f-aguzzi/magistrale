
Ipotesi:

- canale senza memoria $\mathcal X, \mathcal Y, P_{Y|X}(y|x)$
- $\mathcal C = \{\underline x_1, ..., \underline x_M\}$, $\frac{\log_2 M} N = R$ bit/uso di canale
- ricevitore ML
- $\underline x \in \mathcal C$ scelte a caso con $P_{\underline X}(\underline x) = \prod_{n=1}^N P_X(x_n)$

$$\mathbb E[P_{\mathcal C}] \le 2^{NR \rho} \cdot 2^{-NE_0(\rho)} = 2^{-N(E_0(\rho)-\rho R)} \le 2^{-R \cdot E(R)} \qquad 0 \le \rho \le 1$$
$$E_0(\rho) = -\log_2 \sum_{y \in \mathcal Y} \left( \sum_{x \in \mathcal X} P_X(x) P_{Y|X}(y|x)^{\frac 1 {1+\rho}} \right)^{1+\rho}$$

dove $E(R)$, chiamato *esponente d'errore*, è definito come
$$E(R) \triangleq \underset{0 \le \rho \le 1}{\max} E_0(\rho) - \rho R.$$
dove $E_0(\rho)$ è tale che:

1. $E_0(0) = -\log_2 \sum_{y \in \mathcal Y} P_Y(y) = 0$
2. $\sum_x P_X(x) P_{Y|X}(y|x)^{\frac 1 {1+\rho}}  = \mathbb E_X \left[ P_{Y|X}^{\frac 1 {1+\rho}} \right]$ $\le$ $\left( \mathbb E_X[P_{Y|X}(y|x)] \right)^{\frac 1 {1+\rho}}$  (per la disuguaglianza di Jensen, valida per funzioni convesse) quindi
   $$E_0(\rho) \ge -\log \sum_y \left[ \left( \sum_{x \in \mathcal X} P_X(x) P_{Y|X}(y|x) \right)^{\frac 1 {1+\rho}} \right]^{1+\rho} = -\log \sum_y P_Y(y) = 0$$
   e dunque $E_0(\rho) \ge 0$ $\forall \rho$ e $E_0(\rho) \underset{\rho \to 0}{\longrightarrow} 0$ 

Dunque
$$\mathbb E[P_{\mathcal C}] \le 2^{NR \rho} \cdot 2^{-NE_0(\rho)} = 2^{-N(E_0(\rho)-\rho R)} \le 2^{-R \cdot E(R)} \to 0$$

Notiamo che $E_0(\rho) - \rho R$ è un fascio di rette, con intercetta $E_0(\rho)$. Sia l'intercetta che il coefficiente angolare sono proporzionali a $\rho$. Per $\rho$ decrescente le rette tendono ad abbassarsi e "sdraiarsi". $E(R)$, essendo il massimo di questo fascio, va a creare una curva (decrescente) d'inviluppo sulle rette. Il punto di radice sull'asse $x$ è in $\lim_{\rho \to 0} \frac{E_0(\rho)}\rho$.

$$E_0(\rho) = -\log_2 \sum_y \left( \underbrace{\sum_x P_X(x) P_{Y|X}(y|x)^{\frac 1 {1+\rho}}}_{g_y} \right)^{1+\rho} =$$
$$=-\log_2 \underbrace{\sum_y g_y(\rho)^{1+\rho}}_{f(\rho)} =$$

$$\left. \lim_{\rho \to 0} \frac{E_0(\rho)} \rho = \frac{\mathrm d}{\mathrm dp} E_0(\rho) \right|_{\rho = 0} = \left. -\frac 1 {\ln 2} \frac 1 {f(\rho)} \cdot f'(\rho) \right|_{\rho = 0} =$$
$$= \left. -\frac 1 {\ln 2} \cdot \sum_y \frac{\mathrm d}{\mathrm dp} \lfloor g_y(\rho)^{1+\rho} \rfloor \right|_{\rho = 0}$$

(sapendo che:)

$$ \frac{\mathrm d}{\mathrm dp} g_y(\rho)^{1+\rho} = \frac{\mathrm d}{\mathrm d\rho} e^{(1+\rho)\ln g_y(\rho)} = $$
$$ = g_y(\rho)^{1+\rho} \left[ \ln g_y(\rho)+(1+\rho) \frac{g'_y(\rho)}{g_y(\rho)} \right] $$

quindi
$$\lim_{\rho \to 0} \frac{E_0(\rho)}{\rho} = -\frac 1 {\ln 2} \cdot \sum_y g_y(0) \left[ \ln g_y(0) + \frac{g'_y(\rho) |_{\rho=0}}{g_y(9)} \right] =$$
$$ \left. = -\sum_y g_y(0) \log_2 g_y(0)- \frac 1 {\ln 2} \sum_y \sum_x P_X(x) P_{Y|X}(y|x)^{\frac 1 {1+\rho}} \cdot \left( -\frac{1}{(1+\rho)^2} \right) \ln P_{Y|X}(y|x) \right|_{\rho = 0} =$$

(ricordando che $g_y(\rho) = \sum_x P_X(x) P_{Y|X}(y|x)^{\frac 1 {1+\rho}}$)

$$ = \underbrace{\sum_y P_Y(y) \cdot \log_2 \frac 1 {P_Y(y)}}_{H(y)} - \underbrace{\sum_y \sum_x P_X(x) P_{Y|X}(y|x) \cdot \log_2 \frac 1 {P_{Y|X}(y|x)}}_{H(Y|X)} = I(X;Y) $$

e scegliendo $P_X(x) = \arg \max I(X;Y)$ si ottiene che
$$\mathbb E[P_e] \le 2^{-N \cdot E(R)} \underset{N \to \infty} \longrightarrow 0 \qquad \forall R \le C ~~ (\text{ perché } E(R) > 0)$$

Questo teorema:

- indica che aumentando la lunghezza dei codici (quindi accrescendo la ridondanza) si riduce la probabilità di errori
- fornisce un limite teorico per questo fenomeno

Gli "ingredienti" del teorema sono:

1. trasmettere $R < C$
2. ricevitore $ML$
3. $N$ grande (sequenze lunghe)
4. $\mathcal C$ scelto a caso

Volendo portare il tasso d'errore a $10^{-6}$:
$$ \mathbb E[P_e] \le 2^{-N \cdot E(R)} = 10^6 \Leftrightarrow N = 200$$
con $R =0.5$ $\Rightarrow$ $M = 2^{100}$.

Devo memorizzare $2^{100}$ sequenze da 200 bit cioè
$$ 200 \cdot 2^{100} ~ \mathrm{bit} = 2.5 \cdot 10 \cdot 10^{30} ~ \mathrm{byte} = 2.5 \cdot 10^{19} ~ \mathrm{TB}.$$

La ricerca si è focalizzata sul cercare sequenze (non casuali, vista la quantità irragionevole di memoria richiesta) che si avvicinassero ai risultati teorici. Tali progressi non si sono concretizzati fino agli anni '90.

# Introduzione ai codici binari (codifica per canale BSC)

```merm
graph LR
L0[0] -- 1-e --> R0[0]
L0 -- e --> R1[1]
L1[1] -- e --> R0
L1 -- 1-e --> R1
```

Su canale $BSC(\epsilon)$:

$$P_{\underline Y| \underline X}(\underline y |\underline x) = \prod_{n=1}^N P_{Y|X}(y_|x_n) = \varepsilon^d (1-\varepsilon)^{N-d} $$
dove $d$ = distanza di Hamming, $d_H (\underline x , \underline y)$ è il numero di simboli in cui $\underline x$ e $\underline y$ differiscono.

Quindi $\hat {\underline x}_{ML}$ è la sequenza a minima $d_H$ dalla sequenza ricevuta $\underline y$.

1. Come scegliere $\mathcal C$ in modo da garantire grande $d_H(\underline x_1, \underline x_2)$ tra due sequenze $\underline x_1, \underline x_2 ~ \in \mathcal C$?
2. Come individuare $\hat x_{ML} = \underset{\underline x \in \mathcal C}{\arg \min} d_H(\underline x, \underline y)$ ?

## Codici lineari

Sia $\mathcal C = \{ \underline c_1, \underline c_2, ... \underline c_M\}$ dove $\underline c = [c_0 ~ c_1 ~ ... c_{N-1}]$ è una sequenza di bit $c_i \in \{0, 1\}$. $\mathcal C$ è *lineare* se i bit $c_i$ sono combinazioni lineari (in algebra XOR, $1+1=0$) dei bit d'informazione $\underline u = [u_0 ~ ... u_{K-1}]$ dove $M=2^K$ e $\frac K N = R$ è il *rate* del codice.

$\mathcal C$ è univocamente definito dalla *matrice generatrice* ${\underline{\underline G}}^{[K \times N]}$:

$$ \underline u^{[1,K]} \cdot {\underline{\underline G}}^{[K, N]} = \underline c^{[1,N]}, \quad {\underline{\underline G}}^{[i,j]} \in \{0,1\}$$

Proprietà:

1. la sequenza tutta nulla $\underline 0$ $\in \mathcal C$, $\forall \mathcal C$ lineare
2. $\forall \underline c_1, \underline c_2 \in \mathcal C$, $\underline c_1 + \underline c_2 \in \mathcal C$. Questo perché $\underline u_1 {\underline{\underline G}} + \underline u_2 {\underline{\underline G}} = (\underline u_1 + \underline u_2) {\underline{\underline G}} \in \mathcal C$.

> *Definizione:* si chiama *peso di Hamming* il numero $W_H(\underline c)$ di simboli non nulli in $\mathcal C$.

3. se $\mathcal C$ è lineare, la sua distanza minima di Hamming $d$, cioè
   $$ d \triangleq \underset{\underline c_1, \underline c_2 \in \mathcal C}{\min} d_H(\underline c_1, \underline c_2) = \underset{\underline c \in \mathcal C \setminus \{ \underline 0 \} }{\min} W_H(\underline c).$$

> *Definizione:* si chiama *potere correttore* di $\mathcal C$ il massimo numero di errori che si può essere sicuri di riuscire a correggere.
> $$ t = \left \lfloor \frac{d-1}2 \right \rfloor$$

Ad esempio, scegliendo una distanza di Hamming minima pari a 5, tra i seguenti codici sono validi (e appartenenti al codice) solo il primo e l'ultimo:

```
00000...
10000...
110...
111000...
1111000...
1111100...
```

Il secondo e il terzo, se ricevuti, vengono ricondotti al primo. Il quarto e il quinto sono ricondotti al sesto. Il potere correttore è dunque pari a 2.

> *Definizione:* si chiama *potere rivelatore* di $\mathcal C$ il massimo numero di errori che si possono rivelare con certezza.
> $$r = d-1$$

In *modalità mista* correggo fino a $t'$ errori e ne rivelo fino a $r'$, a patto che $r'+d' < d$.

Per le sequenze rivelate ma non corrette si richiede la ritrasmissione.

> *Definizione:* si chiama *matrice di parità* di $\mathcal C$
> $$\underline{\underline H}^{[N, N-K]}, \quad \{\underline{\underline H}_{i,j} \} \in \{0,1\}:$$
> $$  \underline c^{[1,N]} \cdot \underline{\underline H}^{[N, N-K]} = \underline 0^{[1,N-K] } \quad \forall \underline c \in \mathcal C. $$
> Poiché
> $$(\underline u  ~ \underline{\underline G}) \cdot \underline{\underline H} = \underline u (\underline{\underline G} \cdot \underline{\underline H}) = \underline 0 \quad \forall \underline u \Leftrightarrow \underline{\underline G} \cdot \underline{\underline H} = \underline{\underline 0}.$$

> *Definizione:* $\mathcal C$ è sistematico se $\underline u$ è una sottosequenza della sequenza $\underline c$ associata, per esempio:
> $$\underline c^{[1,N]} = \left[ \underline p^{[1,N-K]} ~ \underline u^{[1,K]} \right] \Rightarrow \underline{\underline G}^{[K,N]} = \left[ \underline{\underline P}^{[K,N-K]} ~ \underline{\underline I}^{[K,K]} \right]$$
> $$\Rightarrow \underline{\underline H}^{[N,N-K]} = \begin{bmatrix} \underline{\underline I}^{[N-K, N-K]} \\ \underline{\underline P}^{[K, N-K]}\end{bmatrix} \Rightarrow \underline{\underline G} \cdot \underline{\underline H} = \underline{\underline P} + \underline{\underline P} = \underline{\underline 0}.$$


**Esempio 1: codice SPC** (Simple Parity Check): $SPC(k+1, k)$ (ed eventualmente $d$): aggiunge un bit di parità complessiva. È un codice sistematico.

Per $k=3$ si ha che
$$
\underline{\underline G}^{[3,4]} =
\left[
\begin{matrix}
1 \\ 1 \\ 1
\end{matrix}
\left |
\begin{matrix}
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & 0 & 1
\end{matrix}
\right .
\right]
$$

dove il blocco sinistro è $\underline{\underline P}$, il blocco destro è $\underline{\underline I}$ e invece

$$
\underline{\underline H} = 
\begin{bmatrix}
1 = \underline{\underline I}^{N-K} \\ – – – – – – – \\
1 \\ 1 \\ 1
\end{bmatrix}
$$
 
 *Osservazione 1:* essendo $\underline c = \underline{\underline G} \cdot \underline u = [p ~ \underline u]$ allora
- se $W_H(\underline u)$ è pari, $p = 0$
- se $W_H(\underline u)$ è dispari, $p = 1$
quindi $W_H(\underline c)$ è pari $\forall \underline c \in \mathcal C$.

*Osservazione 2:* $\underline c ~ \underline{\underline H}$  (la somma di tutti i bit di $\underline c$ che sono uguali a 0) è nulla $\Leftrightarrow$ $W_H(\underline c)$ è pari.

*Osservazione 3:* poiché $\underset{\underline c \in \mathcal C}{\min} W_H(\underline c) = 2$ $\Rightarrow$ $d=2$, $r=1$, $t=0$.

**Esempio 2: codice di Hamming.** Codici lineari, sistematici, di parametri $(N, k, d) = (2^{N-K}-1, k, 3)$.

| $N-K$ | $N$ | $K$ |
| ----- | --- | --- |
| 3     | 7   | 4   |
| 4     | 15  | 11  |
| 5     | 31  | 26  |
Per esempio $H(7,4,3)$ è generato da
$$
\underline{\underline G}^{[4,7]} = 
\left[
\begin{matrix}
1 & 1 & 0 \\
0 & 1 & 1 \\
1 & 1 & 1 \\
1 & 0 & 1
\end{matrix}
\left |
\begin{matrix}
1 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 \\
0 & 0 & 1 & 0 \\
0 & 0 & 0 & 1 \\
\end{matrix}
\right .
\right]
$$
mentre
$$
\underline{\underline H} =
\begin{bmatrix}
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & 1 & 0 \\
–  & – & – \\
1 & 1 & 0 \\
0 & 0 & 1 \\
1 & 1 & 1 \\
1 & 0 & 1
\end{bmatrix}
$$

Si ottiene $d=3$, $t = 1$, $r=2$.

Inviato $\underline c$, il messaggio ricevuto è $\underline y = \underline c + \underline e$, dove $\underline e = [0010000]$ $\Rightarrow$ $\underline c \cdot \underline{\underline H} = \underline c ~ \underline{\underline H}  + \underline e ~ \underline{\underline H} = \underline{\underline H}^{(3, :)} \ne \underline 0$.
È possibile determinare che l'errore è in posizione 3 perché le righe sono distinte.

1. $W_H(G(1,:)) = 3 \Rightarrow d \le 3$
2. se $W_H(\underline u) = 2$ essendo righe in $\underline{\underline P}$ distinte $\Rightarrow W_H(\underline c) \ge 3$
3. se $W_H(\underline u) \ge 3$ $\Rightarrow$ $W_H(\underline c) \ge 3$

## Rappresentazione polinomiale dei codici

$$
\begin{matrix}
\underline c = (c_0 ~ c_1 ~ ... ~ c_{N-1})
& \to &
c(x) = c_0 + c_1 x + c_2 x^2 + ... + c_{N-1}x^{N-1}
& \text{grado } \le N-1
\\
\underline u = (u_0 ~ u_1 ~ ... ~ u_{K-1})
& \to &
u(x) = u_0 + u_1 x + u_2 x^2 + ... + u_{K-1}x^{N-1}
& \text{grado } \le K-1
\end{matrix}
$$

Un codice è univocamente definito dal polinomio generatore del codice $g(x)$ di grado $N-K$ come insieme dei polinomi $c(x)$ divisibili per $g(x)$.

Tutti e soli i $c(x) \in \mathcal C$ sono ottenuti facendo
$$u(x)g(x)=c(x) \quad \forall u(x) ~ \text{ di grado } \le K-1$$


>*Osservazione 1:* gli $u(x)$ distinti sono $2^K$.

>*Osservazione 2:* $\mathcal C$ è lineare perché $c_i = \sum_{j=0}^{\min(i, N-K)} g_j \cdot u_{i-j}$. Da $g(x)$ si può sempre ricavare $\underline{\underline G}$ ma non viceversa.

>*Osservazione 3:* l'operazione $c(x) = u(x)g(x)$ realizza una codifica non sistematica.

Per ottenere una codifica sistematica bisogna fare
$$u(x) \cdot x^{N_K} - \mathrm{Resto} \left[ \frac{u(x)\cdot x^{N-K}}{g(x)} \right].$$

**Esempio: codice di Hamming** $H(7,4)$.

$$g(x) = 1 + x + x^3$$
Si prenda $\underline u = [1~0~1~0]$. Si genera $u(x) = 1 + 0x +  1x^2 + 0x^3 = 1 + x^2.$ Dunque
$$ \Rightarrow c(x) = (1+x^2)x^3 - \mathrm{Resto} \left[ \frac{x^5+x^3}{1+x+x^3} \right] $$
Effettuando la divisione:

| $x^5+x^3$<br>$x^5+x^3+x^2$ | $x^3+x+1$         |
| -------------------------- | ----------------- |
| $-x^2$ (resto)             | $x^2$ (quoziente) |

$$c(x) = x^5 + x^3 + x^2 \Rightarrow \underline c = [0~0~1~\underbrace{1~0~1~0}_{\underline u}]$$
La divisione viene effettuata in hardware con $N-K$ flip-flop, un registro a scorrimento retroazionato.

```
           u0u1u2u3-----------|
                              v
|---> [ ] -+-> [ ] --> [ ] ---+
|          |        |         |
|-----------------------------|
g0         g1       g2       g3
```

---

**Tema d'esame 27/8/2008**

$\mathcal C$ binario non sistematico con $N=7$, $g(x) = x^4 + x^3 + x^2 +1$.

Dall'espressione di $g$ si deduce che $N-K = 4$, e da questo che $K=3$, che implica che $u(x)$ abbia grado $\le 2$; $c(x)$ deve dunque avere grado $\le 6$.

1. Quante e quali sono le parole di codice $c(x) \in \mathcal C$?

Si hanno 8 polinomi ($2^k$, $2^3 = 8$) e possono essere calcolati direttamente tramite codifica non sistematica:


| $u(x)$    | $c(x) = g(x)u(x)$     |
| --------- | --------------------- |
| $0$       | $0$                   |
| $1$       | $x^4+x^3+x^2+1$       |
| $x$       | $x^5+x^4+x^3+x$       |
| $x^2$     | $x^6+x^5+x^4+x^2$     |
| $1+x$     | $x^5 + x^2 + x + 1$   |
| $1+x^2$   | $x^6+x^5+x^3+1$       |
| $x+x^2$   | $x^6 + x^3 + x^2 + x$ |
| $1+x+x^2$ | $x^6 + x^4 + x + 1$   |

I $c(x)$ relativi a $u(x)$ "complessi" si possono trovare per combinazione lineare dei valori più semplici. Si noti che termini dello stesso grado si cancellano (algebra XOR).

$$
\Rightarrow ~
\left\{
\begin{matrix*}[l]
\min W_H = 4 = d \\
t = 1 \\
r = 3
\end{matrix*}
\right.
$$

**Tema d'esame del 19 gennaio 2012**

Un codice binario sistematico, rivelatore d'errori, a blocco di lunghezza $N=4$ ha polinomio generatore $g(x)=x+1$.

- Quante e quali sono le parole di codice?

$N-K = 1$ $\to$ $K = 3$.

Quindi abbiamo $2^k = 8$ parole di codice. Gli $u(x)$ devono avere grado $\le K-1 = 2$.

Codice non sistematico (inutile):

| $u(x)$    | $c(x) = g(x)u(x)$ |
| --------- | ----------------- |
| $0$       | $0$               |
| $1$       | $x+1$             |
| $x$       | $x^2+x$           |
| $x^2$     | $x^3+x^2$         |
| $1+x$     | $x^2+1$           |
| $1+x^2$   | $x^3+x^2+x+1$     |
| $x+x^2$   | $x^3+x$           |
| $1+x+x^2$ | $x^3+1$           |

Codice sistematico:

$$c(x) = u(x) x - \mathrm{Resto} \left[ \frac{u(x) \cdot x}{g(x)} \right]$$
Divisioni:

| $x$<br>$x+1$ | $x+1$ |
| ------------ | ----- |
| 1            | 1     |

| $x^2$<br>$x^2+x$ | $x+1$ |
| ---------------- | ----- |
| $x$<br>$x+1$     | $x+1$ |
| 1                | 1     |

| $x^3$<br>$x^3+x^2$ | $x+1$     |
| ------------------ | --------- |
| $x^2$<br>$x^2+x$   | $x^2+x+1$ |
| $x$                |           |
| 1                  |           |

Parole di codice:

| $u(x)$    | $c(x) = g(x)u(x)$ |
| --------- | ----------------- |
| $0$       | $0$               |
| $1$       | $x+1$             |
| $x$       | $x^2+1$           |
| $x^2$     | $x^3+1$           |
| $1+x$     | $x^2+x$           |
| $1+x^2$   | $x^3+x$           |
| $x+x^2$   | $x^3+x^2$         |
| $1+x+x^2$ | $x^3+x^2+x+1$     |

Distanza minima di Hamming: $d=2$. Quindi $t=0$, $r=1$.

Si tratta di un codice a parità semplice: il bit di parità ha valore 1 per le sequenze di lunghezza dispari ed è nullo per le sequenze di lunghezza pari.

Altro tema: 19 febbraio 2009.
